{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/real_estate/ads.csv\")\n",
    "ds_original = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  df = df.drop([\"id\", \"price\"], axis=1)\n",
    "  for column in df.columns:\n",
    "    df[column] = df[column].apply(lambda s: unidecode(s) if type(s) == str else pd.NA)\n",
    "  return df\n",
    "\n",
    "ds = clean_dataset(ds_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_len = ds.shape[0]\n",
    "percent = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 938)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_1_len = int(ds_len * 0.5)\n",
    "ds_2_len = ds_len - ds_1_len\n",
    "ds_1_len, ds_2_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      PARIS 17eme. AVENUE NIEL *** Video disponible ...\n",
       "1      Appartement Paris 3 piece(s) 53 m2. Stephane P...\n",
       "2      Vente Appartement 2 pieces de 31m2 - 75018 Par...\n",
       "3      A vendre, en exclusivite, dans le 11e arrondis...\n",
       "4      Gambetta 2 piece(s) 40 m2. Rue d'Annam, a quel...\n",
       "                             ...                        \n",
       "932    Appartement Paris 3 piece(s) 50 m2 + 24m2 d'es...\n",
       "933    Dpt Paris (75), a vendre PARIS 18EME ARRONDISS...\n",
       "934    Paris Centre - MARAIS - 3 PIECES dans une copr...\n",
       "935    Appartement Paris 2 piece(s) 35.10 m2. 75018 P...\n",
       "936    Appartement 4 pieces (115 m2) en vente dans le...\n",
       "Name: description, Length: 937, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_1_description = ds[\"description\"][:ds_1_len]\n",
    "ds_1_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937     PARIS XIV - ALESIA - APPARTEMENT TRES LUMINEUX...\n",
       "938     Paris XIVeme Triangle d'OR: 3 pieces - rue du ...\n",
       "939     Ternes - 3 pieces - 68,8 m2. Exclusivite.<br>S...\n",
       "940     PARIS 75010, proche de l'hopital Saint-Louis, ...\n",
       "941     Loft avec atelier dans une ancienne serrurerie...\n",
       "                              ...                        \n",
       "1870    Appartement familial - Nation. Le Groupe H&amp...\n",
       "1871    Village de Passy - 5 pieces - 195,51 m2. Villa...\n",
       "1872    Appartement 2 pieces de 46m2 | Rue Clisson | P...\n",
       "1873    Duplex 3 pieces avec terrasse - Pernety XVIeme...\n",
       "1874    PARIS 18EME -AVE CLICHY-Ideal 1er achat. PARIS...\n",
       "Name: description, Length: 938, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_2_description = ds[\"description\"][ds_1_len:]\n",
    "ds_2_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "import fuzzy\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "class IntelektualnyiModul:\n",
    "  def __init__(self, soundex: int = 4, threshold: float = 0.75):\n",
    "    self.soundex = fuzzy.Soundex(soundex)\n",
    "    self.weights = [\n",
    "      (self.token_sort_ratio, 0.5),\n",
    "      (self.soundex_similarity, 0.25),\n",
    "      (self.damerau_levenshtein_distance_normalized, 0.25)\n",
    "    ]\n",
    "    \n",
    "    self.threshold = threshold\n",
    "    self.decisions = [\n",
    "      \"YessðŸŽ€\", \"NoooðŸš¬\",\n",
    "    ]\n",
    "  \n",
    "  def soundex_similarity(self, str1, str2) -> int:\n",
    "    return int(self.soundex(str1) == self.soundex(str2)) * 100\n",
    "  \n",
    "  def similarity_weighted(self, str1, str2, jw_: float = None, soundex_: int = None, levenshtein_: int = None) -> float:\n",
    "    if jw_ is None:\n",
    "      jw_ = self.token_sort_ratio(str1, str2)\n",
    "    if soundex_ is None:\n",
    "      soundex_ = self.soundex_similarity(str1, str2)\n",
    "    if levenshtein_ is None:\n",
    "      levenshtein_ = self.damerau_levenshtein_distance(str1, str2)\n",
    "    \n",
    "    similarity = (\n",
    "      jw_ * 0.5 + \n",
    "      soundex_ * 0.5 + \n",
    "      levenshtein_ * 0.0\n",
    "    )\n",
    "    return round(similarity, 2)\n",
    "  def similarity_weighted_V2(self, str1, str2, weights: list = None) -> float:\n",
    "    if weights is None:\n",
    "      weights = self.weights\n",
    "    similarity = sum([w[0](str1, str2) * w[1] for w in weights])\n",
    "    return round(similarity, 2) \n",
    "  \n",
    "  def hard_decision(self, similarity, strong: bool = False) -> str:\n",
    "    result_index = (similarity < self.threshold) if strong else (similarity <= self.threshold)\n",
    "    return self.decisions[result_index]\n",
    "  \n",
    "  @staticmethod\n",
    "  def damerau_levenshtein_distance(str1, str2) -> int:\n",
    "    return levenshtein_distance(str1, str2)\n",
    "  \n",
    "  @staticmethod\n",
    "  def damerau_levenshtein_distance_normalized(str1, str2):\n",
    "    # ÐžÑÐºÑ–Ð»ÑŒÐºÐ¸ Damerau-Levenshtein - Ñ†Ðµ Ð²Ñ–Ð´ÑÑ‚Ð°Ð½ÑŒ (Ñ‡Ð¸Ð¼ Ð¼ÐµÐ½ÑˆÐµ, Ñ‚Ð¸Ð¼ Ð±Ñ–Ð»ÑŒÑˆÐµ ÑÑ…Ð¾Ð¶Ñ–ÑÑ‚ÑŒ),\n",
    "    # Ð½Ð¾Ñ€Ð¼Ð°Ð»Ñ–Ð·ÑƒÑ”Ð¼Ð¾ Ñ—Ñ— Ð´Ð¾ [0,1] Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ (1 / (1 + distance))\n",
    "    levenshtein_dist = levenshtein_distance(str1, str2)\n",
    "    levenshtein_dist = 1 / (1 + levenshtein_dist)\n",
    "    return levenshtein_dist\n",
    "  \n",
    "  @staticmethod\n",
    "  def token_sort_ratio(str1, str2) -> float:\n",
    "    return fuzz.token_sort_ratio(str1, str2) / 100\n",
    "\n",
    "  def compare(self, str1, str2) -> list:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        list: \n",
    "          soundex_sim, \n",
    "          damerau-levenshtein, \n",
    "          damerau-levenshtein_normalized, \n",
    "          token_sort_ratio, \n",
    "          similarity_weighted_V2\n",
    "    \"\"\"\n",
    "    res_list = [\n",
    "      self.soundex_similarity(str1, str2),\n",
    "      self.damerau_levenshtein_distance(str1, str2),\n",
    "      self.damerau_levenshtein_distance_normalized(str1, str2),\n",
    "      self.token_sort_ratio(str1, str2),\n",
    "      self.similarity_weighted_V2(str1, str2),\n",
    "    ]\n",
    "    return [round(res, 2) for res in res_list]\n",
    "  def compare_row(self, row: pd.Series) -> list:\n",
    "    str1, str2 = row\n",
    "    return self.compare(str1, str2)\n",
    "  \n",
    "modul = IntelektualnyiModul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_column(ds: pd.Series) -> list:\n",
    "  result_dict = {}\n",
    "  ds_len = ds.shape[0]\n",
    "  for i in range(ds_len):\n",
    "    str1 = ds.iloc[i]\n",
    "    max_str = -1\n",
    "    for j in range(i + 1, ds_len):\n",
    "      str2 = ds.iloc[j]\n",
    "      max_str = max(max_str, len(str2))\n",
    "      \n",
    "      row_result = modul.compare(str1, str2)\n",
    "      result_dict[(i, j)] = row_result\n",
    "      #if j % 100 == 0:\n",
    "      #  print(f'\\t{j} rows were compared to row: {i}')\n",
    "    if i % 15 == 0:\n",
    "      print(f'row: {i}/{ds_len} finished comparing | str1_len: {len(str1)}')\n",
    "  return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_different_columns(s1: pd.Series, s2: pd.Series) -> list:\n",
    "  result_dict = {}\n",
    "  s1_len = s1.shape[0]\n",
    "  s2_len = s2.shape[0]\n",
    "\n",
    "  for i in range(s1_len):\n",
    "    str1 = s1.iloc[i]\n",
    "    max_str = -1\n",
    "    for j in range(s2_len):\n",
    "      str2 = s2.iloc[j]\n",
    "      max_str = max(max_str, len(str2))\n",
    "      \n",
    "      row_result = modul.compare(str1, str2)\n",
    "      result_dict[(i, j)] = row_result\n",
    "      #if j % 100 == 0:\n",
    "      #  print(f'\\t{j} rows were compared to row: {i}')\n",
    "    if i % 15 == 0:\n",
    "      print(f'row: {i}/{ds_len} finished comparing | str1_len: {len(str1)}')\n",
    "  return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1_1_description_results = None # compare_column(ds_1_description)\n",
    "\n",
    "save_path = \"comparison_1_1.csv\"\n",
    "# ds_1_1_description_results.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2_2_description_results = None # compare_column(ds_2_description)\n",
    "\n",
    "save_path = \"comparison_2_2.csv\"\n",
    "# ds_2_2_description_results.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 0/1875 finished comparing | str1_len: 973\n",
      "row: 15/1875 finished comparing | str1_len: 1554\n",
      "row: 30/1875 finished comparing | str1_len: 655\n",
      "row: 45/1875 finished comparing | str1_len: 1484\n",
      "row: 60/1875 finished comparing | str1_len: 2236\n",
      "row: 75/1875 finished comparing | str1_len: 785\n",
      "row: 90/1875 finished comparing | str1_len: 546\n",
      "row: 105/1875 finished comparing | str1_len: 1440\n",
      "row: 120/1875 finished comparing | str1_len: 393\n",
      "row: 135/1875 finished comparing | str1_len: 979\n",
      "row: 150/1875 finished comparing | str1_len: 1011\n",
      "row: 165/1875 finished comparing | str1_len: 701\n",
      "row: 180/1875 finished comparing | str1_len: 2406\n",
      "row: 195/1875 finished comparing | str1_len: 838\n",
      "row: 210/1875 finished comparing | str1_len: 895\n",
      "row: 225/1875 finished comparing | str1_len: 1328\n",
      "row: 240/1875 finished comparing | str1_len: 1135\n",
      "row: 255/1875 finished comparing | str1_len: 930\n",
      "row: 270/1875 finished comparing | str1_len: 546\n",
      "row: 285/1875 finished comparing | str1_len: 1585\n",
      "row: 300/1875 finished comparing | str1_len: 667\n",
      "row: 315/1875 finished comparing | str1_len: 517\n",
      "row: 330/1875 finished comparing | str1_len: 2728\n",
      "row: 345/1875 finished comparing | str1_len: 1615\n",
      "row: 360/1875 finished comparing | str1_len: 596\n",
      "row: 375/1875 finished comparing | str1_len: 489\n",
      "row: 390/1875 finished comparing | str1_len: 700\n",
      "row: 405/1875 finished comparing | str1_len: 454\n",
      "row: 420/1875 finished comparing | str1_len: 592\n",
      "row: 435/1875 finished comparing | str1_len: 1467\n",
      "row: 450/1875 finished comparing | str1_len: 666\n",
      "row: 465/1875 finished comparing | str1_len: 1094\n",
      "row: 480/1875 finished comparing | str1_len: 927\n",
      "row: 495/1875 finished comparing | str1_len: 529\n",
      "row: 510/1875 finished comparing | str1_len: 674\n",
      "row: 525/1875 finished comparing | str1_len: 687\n",
      "row: 540/1875 finished comparing | str1_len: 1326\n",
      "row: 555/1875 finished comparing | str1_len: 435\n",
      "row: 570/1875 finished comparing | str1_len: 1020\n",
      "row: 585/1875 finished comparing | str1_len: 2178\n",
      "row: 600/1875 finished comparing | str1_len: 973\n",
      "row: 615/1875 finished comparing | str1_len: 454\n",
      "row: 630/1875 finished comparing | str1_len: 869\n",
      "row: 645/1875 finished comparing | str1_len: 738\n",
      "row: 660/1875 finished comparing | str1_len: 1554\n",
      "row: 675/1875 finished comparing | str1_len: 785\n",
      "row: 690/1875 finished comparing | str1_len: 699\n",
      "row: 705/1875 finished comparing | str1_len: 623\n",
      "row: 720/1875 finished comparing | str1_len: 1040\n",
      "row: 735/1875 finished comparing | str1_len: 625\n",
      "row: 750/1875 finished comparing | str1_len: 371\n",
      "row: 765/1875 finished comparing | str1_len: 1070\n",
      "row: 780/1875 finished comparing | str1_len: 1097\n",
      "row: 795/1875 finished comparing | str1_len: 997\n",
      "row: 810/1875 finished comparing | str1_len: 1406\n",
      "row: 825/1875 finished comparing | str1_len: 933\n",
      "row: 840/1875 finished comparing | str1_len: 586\n",
      "row: 855/1875 finished comparing | str1_len: 685\n",
      "row: 870/1875 finished comparing | str1_len: 1605\n",
      "row: 885/1875 finished comparing | str1_len: 765\n",
      "row: 900/1875 finished comparing | str1_len: 1686\n",
      "row: 915/1875 finished comparing | str1_len: 1298\n",
      "row: 930/1875 finished comparing | str1_len: 1530\n"
     ]
    }
   ],
   "source": [
    "ds_1_2_description_results = compare_different_columns(ds_1_description, ds_2_description)\n",
    "\n",
    "ds_1_2_description_results = pd.DataFrame(ds_1_2_description_results).T\n",
    "\n",
    "save_path = \"comparison_1_2.csv\"\n",
    "ds_1_2_description_results.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878906, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_1_2 = pd.read_csv(\"comparison_1_2.csv\").rename({\n",
    "  \"Unnamed: 0\": \"first_row\",\n",
    "  \"Unnamed: 1\": \"second_row\",\n",
    "  \"0\": \"soundex_sim\", \n",
    "  \"1\": \"damerau-levenshtein\", \n",
    "  \"2\": \"damerau-levenshtein_normalized\", \n",
    "  \"3\": \"token_sort_ratio\", \n",
    "  \"4\": \"similarity_weighted_V2\"\n",
    "}, axis=1)\n",
    "ds_1_2.head()\n",
    "ds_1_2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
